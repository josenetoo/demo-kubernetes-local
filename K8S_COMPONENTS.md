# Componentes Kubernetes: Guia Conceitual

Este documento explica os principais componentes do Kubernetes com exemplos prÃ¡ticos baseados neste projeto.

> ğŸ“š **Para boas prÃ¡ticas e checklists de implementaÃ§Ã£o**, consulte: [K8S_BEST_PRACTICES.md](./K8S_BEST_PRACTICES.md)

---

## ğŸ“‹ Ãndice
1. [Pod](#1-pod)
2. [Deployment](#2-deployment)
3. [StatefulSet](#3-statefulset)
4. [Probes (Health Checks)](#4-probes-health-checks)
5. [Service](#5-service)
6. [ConfigMap](#6-configmap)
7. [Secret](#7-secret)
8. [PersistentVolume (PV) e PersistentVolumeClaim (PVC)](#8-persistentvolume-pv-e-persistentvolumeclaim-pvc)
9. [HorizontalPodAutoscaler (HPA)](#9-horizontalpodautoscaler-hpa)
10. [ComparaÃ§Ã£o entre Componentes](#10-comparaÃ§Ã£o-entre-componentes)

---

## 1. Pod

### ğŸ¯ Conceito
O **Pod** Ã© a menor unidade executÃ¡vel no Kubernetes. Representa um ou mais containers que compartilham:
- Namespace de rede (mesmo IP)
- Volumes de armazenamento
- Contexto de execuÃ§Ã£o

### ğŸ”‘ CaracterÃ­sticas
- **EfÃªmero**: Pods podem ser criados/destruÃ­dos a qualquer momento
- **ImutÃ¡vel**: NÃ£o se atualiza um Pod, cria-se um novo
- **EndereÃ§o IP Ãºnico**: Cada Pod recebe um IP interno do cluster
- **Compartilhamento**: Containers no mesmo Pod compartilham localhost

### ğŸ“¦ Exemplo PrÃ¡tico (deste projeto)
```yaml
# Pod criado automaticamente pelo Deployment
metadata:
  labels:
    app: demo-app
spec:
  containers:
    - name: demo-app
      image: demo-app:local
      ports:
        - containerPort: 8080
      resources:
        requests:
          cpu: "50m"
          memory: "64Mi"
        limits:
          cpu: "250m"
          memory: "128Mi"
```

### ğŸ” Comandos Ãšteis
```bash
# Listar pods
kubectl get pods -l app=demo-app

# Detalhes de um pod
kubectl describe pod <pod-name>

# Logs de um pod
kubectl logs <pod-name>

# Executar comando dentro do pod
kubectl exec -it <pod-name> -- /bin/sh
```

### âš ï¸ Quando NÃƒO usar diretamente
- **Nunca** crie Pods diretamente em produÃ§Ã£o
- Use **Deployments** ou **StatefulSets** para gerenciar Pods
- Pods diretos nÃ£o tÃªm auto-recuperaÃ§Ã£o

---

## 2. Deployment

### ğŸ¯ Conceito
O **Deployment** Ã© um controlador que gerencia ReplicaSets e Pods, garantindo:
- NÃºmero desejado de rÃ©plicas
- EstratÃ©gias de atualizaÃ§Ã£o (rolling update)
- Rollback automÃ¡tico em caso de falha
- Auto-recuperaÃ§Ã£o (self-healing)

### ğŸ”‘ CaracterÃ­sticas
- **Declarativo**: VocÃª declara o estado desejado, o Kubernetes garante
- **Rolling Updates**: Atualiza Pods gradualmente sem downtime
- **Rollback**: Pode reverter para versÃµes anteriores
- **Escalabilidade**: Ajusta nÃºmero de rÃ©plicas facilmente

### ğŸ“¦ Exemplo PrÃ¡tico (deste projeto)
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: demo-app
spec:
  replicas: 2                    # Estado desejado: 2 Pods
  selector:
    matchLabels:
      app: demo-app               # Seleciona Pods com este label
  template:                       # Template do Pod
    metadata:
      labels:
        app: demo-app
    spec:
      containers:
        - name: demo-app
          image: demo-app:local
          ports:
            - containerPort: 8080
          envFrom:
            - configMapRef:
                name: demo-config
            - secretRef:
                name: demo-secret
          resources:
            requests:
              cpu: "50m"
              memory: "64Mi"
            limits:
              cpu: "250m"
              memory: "128Mi"
          readinessProbe:         # Verifica se estÃ¡ pronto para receber trÃ¡fego
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 2
            periodSeconds: 5
          livenessProbe:          # Verifica se estÃ¡ saudÃ¡vel
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 10
```

### ğŸ” Comandos Ãšteis
```bash
# Listar deployments
kubectl get deployments

# Escalar manualmente
kubectl scale deployment demo-app --replicas=3

# Atualizar imagem
kubectl set image deployment/demo-app demo-app=demo-app:v2

# Ver status do rollout
kubectl rollout status deployment/demo-app

# HistÃ³rico de rollouts
kubectl rollout history deployment/demo-app

# Reverter para versÃ£o anterior
kubectl rollout undo deployment/demo-app
```

### ğŸ†š Deployment vs Pod Direto

| Aspecto | Pod Direto | Deployment |
|---------|-----------|------------|
| **Auto-recuperaÃ§Ã£o** | âŒ NÃ£o | âœ… Sim |
| **Escalabilidade** | âŒ Manual | âœ… AutomÃ¡tica |
| **Rolling Updates** | âŒ NÃ£o | âœ… Sim |
| **Rollback** | âŒ NÃ£o | âœ… Sim |
| **Uso em ProduÃ§Ã£o** | âŒ Evitar | âœ… Recomendado |

---

## 3. StatefulSet

### ğŸ¯ Conceito
O **StatefulSet** Ã© um controlador para aplicaÃ§Ãµes **stateful** (com estado), garantindo:
- **Identidade estÃ¡vel**: Cada Pod tem nome previsÃ­vel e persistente
- **Ordem de criaÃ§Ã£o/exclusÃ£o**: Pods sÃ£o criados/deletados em ordem sequencial
- **Storage persistente**: Cada Pod tem seu prÃ³prio volume persistente
- **DNS estÃ¡vel**: Cada Pod tem hostname Ãºnico e previsÃ­vel

### ğŸ”‘ CaracterÃ­sticas
- **Identidade persistente**: Pod `mysql-0`, `mysql-1`, `mysql-2` (nomes fixos)
- **Ordem garantida**: Pods iniciam/terminam em ordem (0 â†’ 1 â†’ 2)
- **Storage dedicado**: Cada Pod tem seu prÃ³prio PVC
- **Network identity**: Hostname estÃ¡vel para cada Pod

### ğŸ†š StatefulSet vs Deployment

| Aspecto | Deployment | StatefulSet |
|---------|-----------|-------------|
| **Tipo de App** | Stateless | Stateful |
| **Nome dos Pods** | AleatÃ³rio (hash) | PrevisÃ­vel (ordinal) |
| **Ordem de criaÃ§Ã£o** | Paralela | Sequencial |
| **Storage** | Compartilhado ou efÃªmero | Persistente por Pod |
| **Network Identity** | EfÃªmero | EstÃ¡vel |
| **Uso tÃ­pico** | APIs, Web apps | Bancos, Kafka, Redis |

### ğŸ“¦ Exemplo PrÃ¡tico: MySQL StatefulSet

```yaml
apiVersion: v1
kind: Service
metadata:
  name: mysql
spec:
  clusterIP: None          # Headless Service (sem ClusterIP)
  selector:
    app: mysql
  ports:
    - port: 3306
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql
spec:
  serviceName: mysql       # Headless Service para DNS estÃ¡vel
  replicas: 3
  selector:
    matchLabels:
      app: mysql
  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
        - name: mysql
          image: mysql:8.0
          ports:
            - containerPort: 3306
          env:
            - name: MYSQL_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: mysql-secret
                  key: password
          volumeMounts:
            - name: data
              mountPath: /var/lib/mysql
  volumeClaimTemplates:    # Template de PVC para cada Pod
    - metadata:
        name: data
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 10Gi
```

### ğŸ”§ Como Funciona

#### Nomes dos Pods (PrevisÃ­veis)
```bash
# Deployment (aleatÃ³rio)
demo-app-7d8f9c5b4-x7k2m
demo-app-7d8f9c5b4-9p3qr

# StatefulSet (ordinal)
mysql-0
mysql-1
mysql-2
```

#### DNS EstÃ¡vel (Headless Service)
```bash
# Cada Pod tem DNS Ãºnico
mysql-0.mysql.default.svc.cluster.local
mysql-1.mysql.default.svc.cluster.local
mysql-2.mysql.default.svc.cluster.local

# AplicaÃ§Ã£o pode conectar diretamente ao Pod especÃ­fico
mysql -h mysql-0.mysql.default.svc.cluster.local
```

#### Storage Persistente por Pod
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         StatefulSet: mysql              â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”‚ mysql-0  â”‚  â”‚ mysql-1  â”‚  â”‚ mysql-2  â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
â”‚       â”‚             â”‚             â”‚
â”‚  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
â”‚  â”‚ PVC-0    â”‚  â”‚ PVC-1    â”‚  â”‚ PVC-2    â”‚
â”‚  â”‚ 10Gi     â”‚  â”‚ 10Gi     â”‚  â”‚ 10Gi     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“Š Ordem de CriaÃ§Ã£o/ExclusÃ£o

**Scale Up (0 â†’ 3)**:
```
1. Cria mysql-0 â†’ Aguarda Ready
2. Cria mysql-1 â†’ Aguarda Ready (apÃ³s mysql-0)
3. Cria mysql-2 â†’ Aguarda Ready (apÃ³s mysql-1)
```

**Scale Down (3 â†’ 1)**:
```
1. Deleta mysql-2 (ordem reversa)
2. Deleta mysql-1 (apÃ³s mysql-2 deletado)
3. mysql-0 permanece
```

### ğŸ¯ Casos de Uso

#### âœ… Quando usar StatefulSet
- **Bancos de dados**: MySQL, PostgreSQL, MongoDB
- **Message queues**: Kafka, RabbitMQ, NATS
- **Cache distribuÃ­do**: Redis Cluster, Memcached
- **Sistemas de coordenaÃ§Ã£o**: ZooKeeper, etcd, Consul
- **AplicaÃ§Ãµes que precisam de**:
  - Identidade de rede estÃ¡vel
  - Storage persistente por instÃ¢ncia
  - Ordem de inicializaÃ§Ã£o/terminaÃ§Ã£o

#### âŒ Quando NÃƒO usar StatefulSet
- APIs REST stateless
- Web servers (Nginx, Apache)
- Workers de processamento
- AplicaÃ§Ãµes que nÃ£o mantÃªm estado local

### ğŸ” Comandos Ãšteis

```bash
# Listar StatefulSets
kubectl get statefulsets
kubectl get sts

# Ver detalhes
kubectl describe sts mysql

# Ver Pods (ordem ordinal)
kubectl get pods -l app=mysql
# mysql-0   1/1     Running
# mysql-1   1/1     Running
# mysql-2   1/1     Running

# Escalar
kubectl scale sts mysql --replicas=5

# Ver PVCs criados automaticamente
kubectl get pvc
# data-mysql-0   Bound    10Gi
# data-mysql-1   Bound    10Gi
# data-mysql-2   Bound    10Gi

# Deletar StatefulSet (mantÃ©m PVCs)
kubectl delete sts mysql

# Deletar StatefulSet E PVCs
kubectl delete sts mysql
kubectl delete pvc -l app=mysql

# Conectar a Pod especÃ­fico
kubectl exec -it mysql-0 -- mysql -u root -p

# Ver logs de Pod especÃ­fico
kubectl logs mysql-1
```

### ğŸ¯ Exemplo: MySQL Master-Slave

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql
spec:
  serviceName: mysql
  replicas: 3
  selector:
    matchLabels:
      app: mysql
  template:
    metadata:
      labels:
        app: mysql
    spec:
      initContainers:
        - name: init-mysql
          image: mysql:8.0
          command:
            - bash
            - "-c"
            - |
              set -ex
              # mysql-0 = master, mysql-1+ = slaves
              [[ $(hostname) =~ -([0-9]+)$ ]] || exit 1
              ordinal=${BASH_REMATCH[1]}
              if [[ $ordinal -eq 0 ]]; then
                echo "Configurando como MASTER"
                cp /mnt/config-map/master.cnf /mnt/conf.d/
              else
                echo "Configurando como SLAVE"
                cp /mnt/config-map/slave.cnf /mnt/conf.d/
              fi
          volumeMounts:
            - name: conf
              mountPath: /mnt/conf.d
            - name: config-map
              mountPath: /mnt/config-map
      containers:
        - name: mysql
          image: mysql:8.0
          ports:
            - containerPort: 3306
          volumeMounts:
            - name: data
              mountPath: /var/lib/mysql
            - name: conf
              mountPath: /etc/mysql/conf.d
      volumes:
        - name: conf
          emptyDir: {}
        - name: config-map
          configMap:
            name: mysql-config
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 10Gi
```

### ğŸ”’ Garantias do StatefulSet

```bash
# 1. Identidade EstÃ¡vel
Pod deletado â†’ Recriado com MESMO nome
mysql-1 deletado â†’ mysql-1 recriado (nÃ£o mysql-1-xyz)

# 2. Storage Persistente
Pod deletado â†’ PVC PERMANECE
Pod recriado â†’ Conecta ao MESMO PVC

# 3. Ordem Sequencial
Scale up: 0 â†’ 1 â†’ 2 (aguarda cada um ficar ready)
Scale down: 2 â†’ 1 â†’ 0 (ordem reversa)

# 4. DNS EstÃ¡vel
Pod recriado â†’ MESMO hostname DNS
mysql-1.mysql.default.svc.cluster.local (sempre)
```

### ğŸ“ Resumo RÃ¡pido

| Aspecto | Valor |
|---------|-------|
| **Quando usar** | Apps stateful (DB, Kafka, Redis) |
| **Nome dos Pods** | PrevisÃ­vel (mysql-0, mysql-1) |
| **Storage** | Persistente por Pod (PVC dedicado) |
| **Ordem** | Sequencial (0 â†’ 1 â†’ 2) |
| **DNS** | EstÃ¡vel (pod.service.namespace.svc) |
| **Complexidade** | Alta (use apenas se necessÃ¡rio) |

---

## 4. Probes (Health Checks)

### ğŸ¯ Conceito
**Probes** sÃ£o verificaÃ§Ãµes de saÃºde que o Kubernetes executa periodicamente nos containers para determinar seu estado. Existem **3 tipos** de probes, cada um com uma responsabilidade especÃ­fica.

### ğŸ”‘ Tipos de Probes

#### 3.1 Liveness Probe (EstÃ¡ Vivo?)
**Pergunta**: "O container estÃ¡ travado ou em deadlock?"

- **PropÃ³sito**: Detectar se o container estÃ¡ em um estado irrecuperÃ¡vel
- **AÃ§Ã£o em falha**: **Reinicia o container**
- **Quando usar**: Detectar deadlocks, travamentos, processos zumbis
- **Exemplo**: AplicaÃ§Ã£o travou em loop infinito

```yaml
livenessProbe:
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 5    # Aguarda 5s apÃ³s o start
  periodSeconds: 10         # Verifica a cada 10s
  timeoutSeconds: 1         # Timeout de 1s
  failureThreshold: 3       # Reinicia apÃ³s 3 falhas consecutivas
```

**CenÃ¡rio Real**:
```
Container inicia â†’ Aguarda 5s â†’ Verifica /health a cada 10s
âœ… /health retorna 200 â†’ Container OK
âŒ /health falha 3x seguidas â†’ Kubernetes REINICIA o container
```

#### 3.2 Readiness Probe (EstÃ¡ Pronto?)
**Pergunta**: "O container estÃ¡ pronto para receber trÃ¡fego?"

- **PropÃ³sito**: Determinar se o Pod deve receber requisiÃ§Ãµes
- **AÃ§Ã£o em falha**: **Remove do Service** (nÃ£o recebe trÃ¡fego)
- **Quando usar**: Aquecimento de cache, conexÃ£o com DB, carregamento de dados
- **Exemplo**: AplicaÃ§Ã£o iniciando, conectando ao banco

```yaml
readinessProbe:
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 2    # Aguarda 2s apÃ³s o start
  periodSeconds: 5          # Verifica a cada 5s
  timeoutSeconds: 1         # Timeout de 1s
  failureThreshold: 3       # Remove do Service apÃ³s 3 falhas
```

**CenÃ¡rio Real**:
```
Container inicia â†’ Aguarda 2s â†’ Verifica /health a cada 5s
âœ… /health retorna 200 â†’ Pod recebe trÃ¡fego do Service
âŒ /health falha â†’ Pod NÃƒO recebe trÃ¡fego (mas nÃ£o reinicia)
âœ… /health volta a funcionar â†’ Pod volta a receber trÃ¡fego
```

#### 3.3 Startup Probe (JÃ¡ Iniciou?)
**Pergunta**: "O container jÃ¡ terminou de inicializar?"

- **PropÃ³sito**: Dar tempo extra para containers com inicializaÃ§Ã£o lenta
- **AÃ§Ã£o em falha**: **Reinicia o container** (se nÃ£o iniciar a tempo)
- **Quando usar**: AplicaÃ§Ãµes legadas, inicializaÃ§Ã£o muito lenta (>30s)
- **Exemplo**: AplicaÃ§Ã£o Java com startup de 2 minutos

```yaml
startupProbe:
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 0
  periodSeconds: 10
  failureThreshold: 30      # 30 * 10s = 5 minutos para iniciar
```

**CenÃ¡rio Real**:
```
Container inicia â†’ Verifica /health a cada 10s
âŒ Pode falhar atÃ© 30x (5 minutos total)
âœ… Quando /health retorna 200 â†’ Startup OK
â†’ Liveness e Readiness comeÃ§am a funcionar
âŒ Se falhar 30x â†’ Kubernetes REINICIA o container
```

### ğŸ†š ComparaÃ§Ã£o entre Probes

| Aspecto | Liveness | Readiness | Startup |
|---------|----------|-----------|---------|
| **Pergunta** | EstÃ¡ vivo? | EstÃ¡ pronto? | JÃ¡ iniciou? |
| **Falha â†’ AÃ§Ã£o** | Reinicia container | Remove do Service | Reinicia container |
| **Quando verifica** | Durante toda vida | Durante toda vida | Apenas no inÃ­cio |
| **Bloqueia outros** | NÃ£o | NÃ£o | Sim (bloqueia Liveness/Readiness) |
| **Uso tÃ­pico** | Detectar deadlock | Controlar trÃ¡fego | Apps com startup lento |
| **ObrigatÃ³rio?** | âš ï¸ Recomendado | âœ… Essencial | âš™ï¸ Opcional |

### ğŸ“¦ Exemplo Completo (deste projeto)

```yaml
spec:
  containers:
    - name: demo-app
      image: demo-app:local
      ports:
        - containerPort: 8080
      
      # 1. Readiness: Controla se recebe trÃ¡fego
      readinessProbe:
        httpGet:
          path: /health
          port: 8080
        initialDelaySeconds: 2
        periodSeconds: 5
        timeoutSeconds: 1
        failureThreshold: 3
      
      # 2. Liveness: Detecta se travou
      livenessProbe:
        httpGet:
          path: /health
          port: 8080
        initialDelaySeconds: 5
        periodSeconds: 10
        timeoutSeconds: 1
        failureThreshold: 3
```

### ğŸ”§ Tipos de VerificaÃ§Ã£o

#### HTTP GET (usado neste projeto)
```yaml
httpGet:
  path: /health
  port: 8080
  httpHeaders:
    - name: Custom-Header
      value: Awesome
```

#### TCP Socket
```yaml
tcpSocket:
  port: 8080
```

#### Exec (comando)
```yaml
exec:
  command:
    - cat
    - /tmp/healthy
```

### ğŸ“Š Fluxo de Vida do Pod com Probes

**1. InicializaÃ§Ã£o**:
```
Pod criado â†’ Startup Probe (se configurado) â†’ Running
```

**2. Readiness Check**:
```
Readiness OK â†’ Adicionado ao Service â†’ Recebe trÃ¡fego
Readiness Falha â†’ Removido do Service â†’ NÃƒO recebe trÃ¡fego
```

**3. Liveness Check (contÃ­nuo)**:
```
Liveness OK â†’ Pod continua rodando
Liveness Falha 3x â†’ Kubernetes REINICIA o container
```

**4. CenÃ¡rio: DB Desconectou**:
```
DB desconecta â†’ Readiness falha â†’ Pod removido do Service
DB reconecta â†’ Readiness OK â†’ Pod volta a receber trÃ¡fego
```

### ğŸ¯ CenÃ¡rios PrÃ¡ticos

#### CenÃ¡rio 1: AplicaÃ§Ã£o Travou (Liveness)
```
SituaÃ§Ã£o: AplicaÃ§Ã£o entrou em deadlock
Probe: Liveness falha 3x consecutivas
AÃ§Ã£o: Kubernetes REINICIA o container
Resultado: AplicaÃ§Ã£o volta a funcionar
```

#### CenÃ¡rio 2: Banco Desconectou (Readiness)
```
SituaÃ§Ã£o: ConexÃ£o com banco de dados perdida
Probe: Readiness falha
AÃ§Ã£o: Pod REMOVIDO do Service (nÃ£o recebe trÃ¡fego)
Resultado: RequisiÃ§Ãµes vÃ£o apenas para Pods saudÃ¡veis
Quando: ConexÃ£o volta â†’ Readiness OK â†’ Pod volta a receber trÃ¡fego
```

#### CenÃ¡rio 3: Deploy com Rolling Update
```
1. Novo Pod criado (v2)
2. Readiness Probe verifica se estÃ¡ pronto
3. âŒ Ainda nÃ£o pronto â†’ NÃ£o recebe trÃ¡fego
4. âœ… Pronto â†’ ComeÃ§a a receber trÃ¡fego
5. Pod antigo (v1) Ã© terminado
Resultado: Zero downtime
```

#### CenÃ¡rio 4: Startup Lento (Startup)
```
SituaÃ§Ã£o: AplicaÃ§Ã£o Java leva 3 minutos para iniciar
Sem Startup Probe: Liveness mata o container antes de iniciar
Com Startup Probe: Aguarda atÃ© 5 minutos (30 * 10s)
Resultado: AplicaÃ§Ã£o tem tempo suficiente para iniciar
```

### ğŸ” Comandos de Debug

```bash
# Ver eventos dos Probes
kubectl describe pod <pod-name>
# Procure por: Liveness probe failed, Readiness probe failed

# Ver logs do container
kubectl logs <pod-name>

# Ver status de readiness
kubectl get pods
# READY 0/1 = Readiness falhou
# READY 1/1 = Readiness OK

# Ver endpoints do Service (Pods prontos)
kubectl get endpoints demo-app

# ForÃ§ar falha de Readiness (teste)
kubectl exec <pod-name> -- rm /tmp/healthy
```

### ğŸ“ Resumo RÃ¡pido

| Probe | Quando Usar | Falha â†’ AÃ§Ã£o |
|-------|-------------|--------------|
| **Readiness** | Sempre | Remove do Service |
| **Liveness** | Detectar travamentos | Reinicia container |
| **Startup** | Apps com startup lento | Reinicia container |

**Regra de Ouro**: 
- **Readiness** = Controla trÃ¡fego (essencial)
- **Liveness** = Detecta problemas graves (opcional)
- **Startup** = DÃ¡ tempo para iniciar (raro)

---

## 4. Service

### ğŸ¯ Conceito
O **Service** Ã© uma abstraÃ§Ã£o que expÃµe um conjunto de Pods como um serviÃ§o de rede, fornecendo:
- **IP estÃ¡vel**: Pods tÃªm IPs efÃªmeros, Services tÃªm IPs fixos
- **Load Balancing**: Distribui trÃ¡fego entre Pods
- **Service Discovery**: Nome DNS interno para o serviÃ§o

### ğŸ”‘ Tipos de Service

#### 4.1 ClusterIP (padrÃ£o) - Apenas Interno

**Quando usar**: ComunicaÃ§Ã£o entre serviÃ§os DENTRO do cluster

```yaml
apiVersion: v1
kind: Service
metadata:
  name: backend-api
spec:
  type: ClusterIP          # PadrÃ£o, pode omitir
  selector:
    app: backend-api
  ports:
    - port: 80             # Porta do Service
      targetPort: 8080     # Porta do container
```

**Como funciona**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Cluster Kubernetes            â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Pod A    â”‚â”€â”€â”€â”€â”€â–¶â”‚ Service      â”‚   â”‚
â”‚  â”‚ Frontend â”‚      â”‚ ClusterIP    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚ 10.96.0.10   â”‚   â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚            â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                    â”‚ Pod B        â”‚   â”‚
â”‚                    â”‚ Backend      â”‚   â”‚
â”‚                    â”‚ :8080        â”‚   â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        âŒ Sem acesso externo
```

**Acesso**:
```bash
# Dentro do cluster
curl http://backend-api.default.svc.cluster.local

# DNS curto (mesmo namespace)
curl http://backend-api
```

**Casos de uso**:
- âœ… Banco de dados (PostgreSQL, MySQL)
- âœ… Cache (Redis, Memcached)
- âœ… APIs internas (nÃ£o expostas publicamente)
- âœ… Message queues (RabbitMQ, Kafka)

---

#### 4.2 NodePort - Acesso via Porta do Node

**Quando usar**: Desenvolvimento local, testes, ambientes sem Load Balancer

```yaml
apiVersion: v1
kind: Service
metadata:
  name: demo-app
spec:
  type: NodePort
  selector:
    app: demo-app
  ports:
    - name: http
      port: 80              # Porta do Service (interna)
      targetPort: 8080      # Porta do container
      nodePort: 30080       # Porta exposta no Node (30000-32767)
```

**Como funciona**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Cluster Kubernetes                 â”‚
â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Node (localhost)                       â”‚   â”‚
â”‚  â”‚                                        â”‚   â”‚
â”‚  â”‚  Porta 30080 â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚
â”‚  â”‚       â”‚                         â”‚     â”‚   â”‚
â”‚  â”‚       â–¼                         â”‚     â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚     â”‚   â”‚
â”‚  â”‚  â”‚ Service     â”‚                â”‚     â”‚   â”‚
â”‚  â”‚  â”‚ NodePort    â”‚                â”‚     â”‚   â”‚
â”‚  â”‚  â”‚ :80         â”‚                â”‚     â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                â”‚     â”‚   â”‚
â”‚  â”‚         â”‚                        â”‚     â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚     â”‚   â”‚
â”‚  â”‚    â”‚ Pod 1   â”‚  â”‚ Pod 2    â”‚   â”‚     â”‚   â”‚
â”‚  â”‚    â”‚ :8080   â”‚  â”‚ :8080    â”‚   â”‚     â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â–²
              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Cliente Externo   â”‚
    â”‚ localhost:30080   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Acesso**:
```bash
# Docker Desktop (localhost)
curl http://localhost:30080

# Cluster real (IP do Node)
curl http://192.168.1.100:30080

# Dentro do cluster (tambÃ©m funciona)
curl http://demo-app.default.svc.cluster.local
```

**Fluxo de requisiÃ§Ã£o**:
```
Cliente â†’ Node:30080 â†’ Service:80 â†’ Pod:8080
```

**Casos de uso**:
- âœ… Desenvolvimento local (Docker Desktop, Minikube)
- âœ… Testes rÃ¡pidos
- âœ… Demos e POCs
- âŒ ProduÃ§Ã£o (use LoadBalancer ou Ingress)

**LimitaÃ§Ãµes**:
- Porta fixa (30000-32767)
- Precisa conhecer IP do Node
- Sem balanceamento externo
- NÃ£o escalÃ¡vel para produÃ§Ã£o

---

#### 4.3 LoadBalancer - IP PÃºblico (Cloud)

**Quando usar**: ProduÃ§Ã£o em cloud providers (AWS, GCP, Azure)

```yaml
apiVersion: v1
kind: Service
metadata:
  name: public-api
spec:
  type: LoadBalancer
  selector:
    app: public-api
  ports:
    - port: 80
      targetPort: 8080
```

**Como funciona**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Cloud Provider                      â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Load Balancer (AWS ELB / GCP LB)           â”‚    â”‚
â”‚  â”‚ IP PÃºblico: 203.0.113.50                   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                   â”‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚         Cluster Kubernetes                 â”‚    â”‚
â”‚  â”‚                                            â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚    â”‚
â”‚  â”‚  â”‚ Service     â”‚                          â”‚    â”‚
â”‚  â”‚  â”‚ LoadBalancerâ”‚                          â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                          â”‚    â”‚
â”‚  â”‚         â”‚                                  â”‚    â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”‚    â”‚
â”‚  â”‚    â”‚ Pod 1   â”‚  â”‚ Pod 2    â”‚  â”‚ Pod 3  â”‚â”‚    â”‚
â”‚  â”‚    â”‚ :8080   â”‚  â”‚ :8080    â”‚  â”‚ :8080  â”‚â”‚    â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–²
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Cliente Internet      â”‚
         â”‚ http://203.0.113.50   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Acesso**:
```bash
# ApÃ³s criaÃ§Ã£o, obter IP pÃºblico
kubectl get svc public-api
# NAME        TYPE           CLUSTER-IP     EXTERNAL-IP      PORT(S)
# public-api  LoadBalancer   10.96.0.20     203.0.113.50     80:31234/TCP

# Acessar via IP pÃºblico
curl http://203.0.113.50
```

**Fluxo de requisiÃ§Ã£o**:
```
Cliente â†’ Load Balancer (IP pÃºblico) â†’ Service â†’ Pods
```

**Casos de uso**:
- âœ… ProduÃ§Ã£o em AWS, GCP, Azure
- âœ… AplicaÃ§Ãµes pÃºblicas (websites, APIs)
- âœ… Alta disponibilidade
- âœ… Balanceamento automÃ¡tico

**Vantagens**:
- IP pÃºblico automÃ¡tico
- Balanceamento de carga externo
- Health checks nativos
- IntegraÃ§Ã£o com cloud provider

**Custo**:
- ğŸ’° Cobra por Load Balancer (AWS ELB ~$20/mÃªs)
- ğŸ’° Cada Service = 1 Load Balancer
- ğŸ’¡ Use Ingress para mÃºltiplos serviÃ§os (1 Load Balancer)

---

#### 4.4 ExternalName - Alias para ServiÃ§o Externo

**Quando usar**: Referenciar serviÃ§os FORA do cluster (APIs externas, DBs gerenciados)

```yaml
apiVersion: v1
kind: Service
metadata:
  name: external-db
spec:
  type: ExternalName
  externalName: mydb.abc123.us-east-1.rds.amazonaws.com
```

**Como funciona**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Cluster Kubernetes                    â”‚
â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Pod      â”‚â”€â”€â”€â”€â”€â–¶â”‚ Service          â”‚       â”‚
â”‚  â”‚ App      â”‚      â”‚ ExternalName     â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚ external-db      â”‚       â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                           â”‚                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ DNS Redirect
                            â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ ServiÃ§o Externo         â”‚
              â”‚ AWS RDS / Cloud SQL     â”‚
              â”‚ mydb.abc123.rds.aws.com â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Acesso**:
```bash
# Dentro do cluster
curl http://external-db.default.svc.cluster.local
# Redireciona para: mydb.abc123.us-east-1.rds.amazonaws.com
```

**Casos de uso**:
- âœ… Banco de dados gerenciado (AWS RDS, Cloud SQL)
- âœ… APIs externas (Stripe, SendGrid)
- âœ… ServiÃ§os legados fora do cluster
- âœ… MigraÃ§Ã£o gradual para Kubernetes

**Exemplo prÃ¡tico**:
```yaml
# Antes: App conecta direto ao RDS
DATABASE_URL=mydb.abc123.rds.amazonaws.com

# Depois: App usa Service interno
DATABASE_URL=external-db.default.svc.cluster.local
# Kubernetes redireciona para o RDS
```

---

### ğŸ†š ComparaÃ§Ã£o Detalhada entre Tipos de Service

| Aspecto | ClusterIP | NodePort | LoadBalancer | ExternalName |
|---------|-----------|----------|--------------|--------------|
| **Acesso Externo** | âŒ NÃ£o | âœ… Sim (porta Node) | âœ… Sim (IP pÃºblico) | â¡ï¸ Redirect |
| **Acesso Interno** | âœ… Sim | âœ… Sim | âœ… Sim | âœ… Sim |
| **IP PÃºblico** | âŒ NÃ£o | âŒ NÃ£o | âœ… Sim | N/A |
| **Porta Fixa** | NÃ£o | âœ… 30000-32767 | NÃ£o | N/A |
| **Load Balancing** | âœ… Interno | âœ… Interno | âœ… Externo + Interno | âŒ NÃ£o |
| **Custo** | Gratuito | Gratuito | ğŸ’° Pago (cloud) | Gratuito |
| **Uso TÃ­pico** | APIs internas | Dev/Test | ProduÃ§Ã£o (cloud) | ServiÃ§os externos |
| **ProduÃ§Ã£o** | âœ… Sim | âŒ NÃ£o | âœ… Sim | âœ… Sim |

### ğŸ¯ Qual Service usar?

```bash
# CenÃ¡rio 1: Banco de dados interno
âœ… ClusterIP
Motivo: NÃ£o precisa ser acessado externamente

# CenÃ¡rio 2: Desenvolvimento local (Docker Desktop)
âœ… NodePort
Motivo: Acesso fÃ¡cil via localhost:30080

# CenÃ¡rio 3: API pÃºblica em produÃ§Ã£o (AWS/GCP)
âœ… LoadBalancer
Motivo: IP pÃºblico, alta disponibilidade

# CenÃ¡rio 4: MÃºltiplos serviÃ§os pÃºblicos
âœ… Ingress (com ClusterIP)
Motivo: 1 Load Balancer para N serviÃ§os (economia)

# CenÃ¡rio 5: Conectar a RDS externo
âœ… ExternalName
Motivo: Abstrai URL externa como Service interno
```

### ğŸ“¦ Exemplo PrÃ¡tico (deste projeto)

```yaml
apiVersion: v1
kind: Service
metadata:
  name: demo-app
spec:
  type: NodePort                # Tipo: NodePort
  selector:
    app: demo-app               # Seleciona Pods com label app=demo-app
  ports:
    - name: http
      port: 80                  # Porta do Service (interna)
      targetPort: 8080          # Porta do container
      nodePort: 30080           # Porta exposta no Node
```

**Funcionamento**:
```
1. Cliente acessa: http://localhost:30080
2. Node redireciona para: Service demo-app:80
3. Service balanceia para: Pods na porta 8080
4. Pod processa e retorna resposta
```

### ğŸ” Comandos Ãšteis

```bash
# Listar services
kubectl get services
kubectl get svc

# Ver detalhes (incluindo IP e Endpoints)
kubectl describe svc demo-app

# Ver Pods associados ao Service
kubectl get endpoints demo-app

# Testar conectividade interna (ClusterIP)
kubectl run test --rm -it --image=busybox -- wget -qO- http://demo-app.default.svc.cluster.local

# Ver IP externo (LoadBalancer)
kubectl get svc demo-app -o jsonpath='{.status.loadBalancer.ingress[0].ip}'

# Port-forward para teste local
kubectl port-forward svc/demo-app 8080:80
# Acessa: http://localhost:8080
```

### ğŸ“ Resumo RÃ¡pido

| Service | Quando Usar | Acesso |
|---------|-------------|--------|
| **ClusterIP** | ServiÃ§os internos | Apenas dentro do cluster |
| **NodePort** | Dev/Test local | `<NodeIP>:<NodePort>` |
| **LoadBalancer** | ProduÃ§Ã£o (cloud) | IP pÃºblico |
| **ExternalName** | ServiÃ§os externos | DNS redirect |

---

## 6. ConfigMap

### ğŸ¯ Conceito
O **ConfigMap** armazena dados de configuraÃ§Ã£o nÃ£o-sensÃ­veis em pares chave-valor, permitindo:
- **SeparaÃ§Ã£o**: ConfiguraÃ§Ã£o separada do cÃ³digo
- **ReutilizaÃ§Ã£o**: Mesmo ConfigMap para mÃºltiplos Pods
- **AtualizaÃ§Ã£o**: Alterar config sem rebuild da imagem

### ğŸ”‘ CaracterÃ­sticas
- **NÃ£o-criptografado**: Dados em texto plano
- **Limite**: 1MB por ConfigMap
- **Tipos de dados**: Strings, arquivos, variÃ¡veis de ambiente

### ğŸ“¦ Exemplo PrÃ¡tico (deste projeto)
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: demo-config
data:
  VERSION: "v1"
  MESSAGE: "Hello from ConfigMap"
```

### ğŸ”§ Formas de Consumir ConfigMap

#### 6.1 Como VariÃ¡veis de Ambiente (usado neste projeto)
```yaml
spec:
  containers:
    - name: demo-app
      envFrom:
        - configMapRef:
            name: demo-config
      # Resultado: VERSION=v1, MESSAGE=Hello from ConfigMap
```

#### 6.2 Como VariÃ¡vel Individual
```yaml
spec:
  containers:
    - name: demo-app
      env:
        - name: APP_VERSION
          valueFrom:
            configMapKeyRef:
              name: demo-config
              key: VERSION
```

#### 6.3 Como Volume (arquivo)
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config-file
data:
  config.json: |
    {
      "database": "postgres",
      "port": 5432
    }
---
spec:
  containers:
    - name: app
      volumeMounts:
        - name: config-volume
          mountPath: /etc/config
  volumes:
    - name: config-volume
      configMap:
        name: app-config-file
  # Resultado: arquivo em /etc/config/config.json
```

### ğŸ” Comandos Ãšteis
```bash
# Listar ConfigMaps
kubectl get configmaps
kubectl get cm

# Ver conteÃºdo
kubectl describe cm demo-config
kubectl get cm demo-config -o yaml

# Criar via comando
kubectl create configmap app-config --from-literal=KEY=value

# Criar de arquivo
kubectl create configmap app-config --from-file=config.json

# Editar
kubectl edit cm demo-config
```

### âš ï¸ Quando NÃƒO usar ConfigMap
- **Dados sensÃ­veis**: Use Secret
- **Dados grandes**: Use Volumes persistentes
- **Dados binÃ¡rios**: Prefira Secrets ou Volumes

---

## 7. Secret

### ğŸ¯ Conceito
O **Secret** armazena dados sensÃ­veis (senhas, tokens, chaves) com:
- **Criptografia**: Dados em base64 (mÃ­nimo)
- **Controle de acesso**: RBAC para limitar quem acessa
- **RotaÃ§Ã£o**: Facilita atualizaÃ§Ã£o de credenciais

### ğŸ”‘ Tipos de Secret

#### 7.1 Opaque (genÃ©rico - usado neste projeto)
```yaml
apiVersion: v1
kind: Secret
metadata:
  name: demo-secret
type: Opaque
stringData:              # Texto plano (convertido para base64)
  SECRET_TOKEN: "s3cr3t-token"
```

#### 7.2 docker-registry (credenciais Docker)
```yaml
apiVersion: v1
kind: Secret
metadata:
  name: docker-creds
type: kubernetes.io/dockerconfigjson
data:
  .dockerconfigjson: <base64-encoded-docker-config>
```

#### 7.3 tls (certificados TLS)
```yaml
apiVersion: v1
kind: Secret
metadata:
  name: tls-secret
type: kubernetes.io/tls
data:
  tls.crt: <base64-cert>
  tls.key: <base64-key>
```

### ğŸ”§ Formas de Consumir Secret

#### 7.4 Como VariÃ¡veis de Ambiente (usado neste projeto)
```yaml
spec:
  containers:
    - name: demo-app
      envFrom:
        - secretRef:
            name: demo-secret
      # Resultado: SECRET_TOKEN=s3cr3t-token
```

#### 7.5 Como Volume (arquivo)
```yaml
spec:
  containers:
    - name: app
      volumeMounts:
        - name: secret-volume
          mountPath: /etc/secrets
          readOnly: true
  volumes:
    - name: secret-volume
      secret:
        secretName: demo-secret
  # Resultado: arquivo em /etc/secrets/SECRET_TOKEN
```

### ğŸ” Comandos Ãšteis
```bash
# Listar secrets
kubectl get secrets

# Ver detalhes (sem valores)
kubectl describe secret demo-secret

# Ver valores (base64)
kubectl get secret demo-secret -o yaml

# Decodificar valor
kubectl get secret demo-secret -o jsonpath='{.data.SECRET_TOKEN}' | base64 -d

# Criar via comando
kubectl create secret generic db-secret --from-literal=password=mypass

# Criar de arquivo
kubectl create secret generic ssh-key --from-file=~/.ssh/id_rsa
```

### ğŸ†š ConfigMap vs Secret

| Aspecto | ConfigMap | Secret |
|---------|-----------|--------|
| **Dados** | NÃ£o-sensÃ­veis | SensÃ­veis |
| **CodificaÃ§Ã£o** | Texto plano | Base64 (mÃ­nimo) |
| **Criptografia** | âŒ NÃ£o | âœ… Opcional (at rest) |
| **Uso** | Configs, flags | Senhas, tokens, chaves |
| **Limite** | 1MB | 1MB |
| **RBAC** | Menos crÃ­tico | CrÃ­tico |

---

## 8. PersistentVolume (PV) e PersistentVolumeClaim (PVC)

### ğŸ¯ Conceito
**PersistentVolume (PV)** e **PersistentVolumeClaim (PVC)** sÃ£o componentes para gerenciar **armazenamento persistente** no Kubernetes:

- **PV (PersistentVolume)**: Recurso de armazenamento no cluster (disco fÃ­sico, NFS, cloud storage)
- **PVC (PersistentVolumeClaim)**: RequisiÃ§Ã£o de armazenamento feita por um Pod

**Analogia**: PV Ã© como um "disco disponÃ­vel" e PVC Ã© como "pedir um disco com X GB"

### ğŸ”‘ CaracterÃ­sticas

#### PersistentVolume (PV)
- **Provisionado pelo admin** ou dinamicamente
- **Independente do Pod**: Sobrevive Ã  exclusÃ£o do Pod
- **Tipos**: Local, NFS, AWS EBS, GCP Persistent Disk, Azure Disk, etc.
- **Ciclo de vida**: Independente do Pod

#### PersistentVolumeClaim (PVC)
- **Criado pelo usuÃ¡rio**: Solicita storage com requisitos especÃ­ficos
- **Bind automÃ¡tico**: Kubernetes encontra PV compatÃ­vel
- **Usado pelo Pod**: Montado como volume no container

### ğŸ“Š Fluxo de Funcionamento

```
1. Admin/StorageClass â†’ Provisiona PV (10Gi) â†’ Estado: Available
2. UsuÃ¡rio â†’ Cria PVC (solicita 5Gi)
3. Kubernetes â†’ Busca PV compatÃ­vel
4. PVC â†” PV â†’ Bind (vincula) â†’ Estado: Bound
5. Pod â†’ Monta PVC como volume â†’ Usa storage persistente
6. Pod deletado â†’ PVC e PV PERMANECEM
7. Novo Pod â†’ Monta mesmo PVC â†’ Dados preservados! âœ…
```

### ğŸ†š PV vs PVC vs Volume

| Aspecto | Volume (emptyDir) | PersistentVolume (PV) | PersistentVolumeClaim (PVC) |
|---------|-------------------|----------------------|----------------------------|
| **PersistÃªncia** | âŒ EfÃªmero | âœ… Persistente | âœ… Persistente |
| **Escopo** | Pod | Cluster | Namespace |
| **Sobrevive ao Pod** | âŒ NÃ£o | âœ… Sim | âœ… Sim |
| **Quem cria** | Definido no Pod | Admin/StorageClass | UsuÃ¡rio |
| **Uso tÃ­pico** | Cache temporÃ¡rio | Storage permanente | Solicitar storage |

### ğŸ“¦ Exemplo 1: PV e PVC Manual

#### 1. Criar PersistentVolume (Admin)

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-local
spec:
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce      # RWO: Um Node por vez
  persistentVolumeReclaimPolicy: Retain
  storageClassName: manual
  hostPath:
    path: /mnt/data      # Path no Node (apenas para dev/test)
```

#### 2. Criar PersistentVolumeClaim (UsuÃ¡rio)

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-app
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi       # Solicita 5Gi (PV tem 10Gi)
  storageClassName: manual
```

#### 3. Usar PVC no Pod

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: app-with-storage
spec:
  containers:
    - name: app
      image: nginx
      volumeMounts:
        - name: storage
          mountPath: /usr/share/nginx/html
  volumes:
    - name: storage
      persistentVolumeClaim:
        claimName: pvc-app    # Referencia o PVC
```

### ğŸ”§ Access Modes (Modos de Acesso)

| Modo | Sigla | DescriÃ§Ã£o | Uso TÃ­pico |
|------|-------|-----------|-----------|
| **ReadWriteOnce** | RWO | Leitura/escrita por **1 Node** | Banco de dados, apps single-instance |
| **ReadOnlyMany** | ROX | Leitura por **mÃºltiplos Nodes** | Assets estÃ¡ticos, configs compartilhadas |
| **ReadWriteMany** | RWX | Leitura/escrita por **mÃºltiplos Nodes** | Shared storage, NFS, CephFS |

**Importante**: Nem todos os tipos de storage suportam todos os modos!

```bash
# AWS EBS: Apenas RWO
# NFS: RWO, ROX, RWX
# Azure Disk: Apenas RWO
# GCP Persistent Disk: Apenas RWO
```

### ğŸ“¦ Exemplo 2: Dynamic Provisioning (StorageClass)

#### 1. Criar StorageClass (provisionamento dinÃ¢mico)

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: fast-ssd
provisioner: kubernetes.io/aws-ebs    # AWS EBS
parameters:
  type: gp3                            # Tipo de disco
  iops: "3000"
  throughput: "125"
allowVolumeExpansion: true
reclaimPolicy: Delete
```

#### 2. Criar PVC (PV criado automaticamente)

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-dynamic
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: fast-ssd    # Usa StorageClass
  resources:
    requests:
      storage: 20Gi
```

**Resultado**: Kubernetes cria automaticamente um PV de 20Gi usando AWS EBS!

#### 3. Usar no Deployment

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mysql
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mysql
  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
        - name: mysql
          image: mysql:8.0
          env:
            - name: MYSQL_ROOT_PASSWORD
              value: password
          volumeMounts:
            - name: mysql-data
              mountPath: /var/lib/mysql
      volumes:
        - name: mysql-data
          persistentVolumeClaim:
            claimName: pvc-dynamic
```

### ğŸ”„ Reclaim Policy (PolÃ­tica de RecuperaÃ§Ã£o)

Determina o que acontece com o PV quando o PVC Ã© deletado:

| Policy | Comportamento | Uso |
|--------|--------------|-----|
| **Retain** | PV permanece (manual cleanup) | ProduÃ§Ã£o (dados importantes) |
| **Delete** | PV Ã© deletado automaticamente | Dev/Test (storage temporÃ¡rio) |
| **Recycle** | PV Ã© limpo e reutilizado (deprecated) | NÃ£o usar |

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-retain
spec:
  capacity:
    storage: 10Gi
  persistentVolumeReclaimPolicy: Retain    # MantÃ©m dados
```

### ğŸ“Š Estados do PV e PVC

#### Estados do PV
```bash
Available  # DisponÃ­vel para bind
Bound      # Vinculado a um PVC
Released   # PVC deletado, mas PV ainda tem dados
Failed     # Erro no provisionamento
```

#### Estados do PVC
```bash
Pending    # Aguardando PV compatÃ­vel
Bound      # Vinculado a um PV
Lost       # PV foi deletado
```

### ğŸ” Comandos Ãšteis

```bash
# Listar PVs (cluster-wide)
kubectl get pv
# NAME       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS
# pv-local   10Gi       RWO            Retain           Bound

# Listar PVCs (namespace)
kubectl get pvc
# NAME       STATUS   VOLUME     CAPACITY   ACCESS MODES
# pvc-app    Bound    pv-local   10Gi       RWO

# Ver detalhes do PV
kubectl describe pv pv-local

# Ver detalhes do PVC
kubectl describe pvc pvc-app

# Ver uso de storage
kubectl get pvc -o custom-columns=NAME:.metadata.name,CAPACITY:.status.capacity.storage,USED:.status.phase

# Deletar PVC (PV pode ser retido ou deletado)
kubectl delete pvc pvc-app

# Listar StorageClasses
kubectl get storageclass
kubectl get sc

# Ver StorageClass padrÃ£o
kubectl get sc -o jsonpath='{.items[?(@.metadata.annotations.storageclass\.kubernetes\.io/is-default-class=="true")].metadata.name}'
```

### ğŸ¯ Exemplo 3: StatefulSet com PVC (volumeClaimTemplates)

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
spec:
  serviceName: postgres
  replicas: 3
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
        - name: postgres
          image: postgres:15
          ports:
            - containerPort: 5432
          env:
            - name: POSTGRES_PASSWORD
              value: password
          volumeMounts:
            - name: data
              mountPath: /var/lib/postgresql/data
  volumeClaimTemplates:    # Cria PVC automaticamente para cada Pod
    - metadata:
        name: data
      spec:
        accessModes: ["ReadWriteOnce"]
        storageClassName: fast-ssd
        resources:
          requests:
            storage: 50Gi
```

**Resultado**:
```bash
# PVCs criados automaticamente
data-postgres-0   Bound   50Gi
data-postgres-1   Bound   50Gi
data-postgres-2   Bound   50Gi

# Cada Pod tem seu prÃ³prio storage persistente!
```

### ğŸ’¾ Tipos de Storage Backends

#### Local (Dev/Test)
```yaml
hostPath:
  path: /mnt/data
  type: DirectoryOrCreate
```

#### NFS (Shared Storage)
```yaml
nfs:
  server: nfs-server.example.com
  path: /exported/path
```

#### AWS EBS (Cloud)
```yaml
awsElasticBlockStore:
  volumeID: vol-0123456789abcdef
  fsType: ext4
```

#### GCP Persistent Disk
```yaml
gcePersistentDisk:
  pdName: my-disk
  fsType: ext4
```

#### Azure Disk
```yaml
azureDisk:
  diskName: my-disk
  diskURI: /subscriptions/.../disks/my-disk
```

### ğŸ¯ CenÃ¡rios PrÃ¡ticos

#### CenÃ¡rio 1: Banco de Dados (MySQL)
```yaml
# PVC para dados do MySQL
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mysql-pvc
spec:
  accessModes: [ReadWriteOnce]
  resources:
    requests:
      storage: 20Gi
  storageClassName: fast-ssd
```

#### CenÃ¡rio 2: Uploads de UsuÃ¡rios (Shared Storage)
```yaml
# PVC compartilhado (requer NFS ou similar)
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: uploads-pvc
spec:
  accessModes: [ReadWriteMany]    # MÃºltiplos Pods
  resources:
    requests:
      storage: 100Gi
  storageClassName: nfs-storage
```

#### CenÃ¡rio 3: Logs Persistentes
```yaml
# PVC para logs
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: logs-pvc
spec:
  accessModes: [ReadWriteOnce]
  resources:
    requests:
      storage: 50Gi
```

### ğŸ“ Resumo RÃ¡pido

| Componente | FunÃ§Ã£o | Criado por | Escopo |
|-----------|--------|-----------|--------|
| **PV** | Storage fÃ­sico | Admin/StorageClass | Cluster |
| **PVC** | RequisiÃ§Ã£o de storage | UsuÃ¡rio | Namespace |
| **StorageClass** | Provisionamento dinÃ¢mico | Admin | Cluster |

**Fluxo**: PVC solicita â†’ StorageClass provisiona â†’ PV criado â†’ PVC vincula â†’ Pod usa

**Regra de Ouro**:
- **Stateless apps**: Sem PVC (use emptyDir se necessÃ¡rio)
- **Stateful apps**: Use PVC + StorageClass
- **StatefulSet**: Use volumeClaimTemplates

---

## 9. HorizontalPodAutoscaler (HPA)

### ğŸ¯ Conceito
O **HPA** escala automaticamente o nÃºmero de Pods baseado em mÃ©tricas, como:
- **CPU**: UtilizaÃ§Ã£o de CPU
- **MemÃ³ria**: UtilizaÃ§Ã£o de memÃ³ria
- **Custom**: MÃ©tricas customizadas (ex: requisiÃ§Ãµes/segundo)

### ğŸ”‘ CaracterÃ­sticas
- **AutomÃ¡tico**: Escala sem intervenÃ§Ã£o manual
- **Baseado em mÃ©tricas**: Requer metrics-server
- **Limites**: Define min/max de rÃ©plicas
- **Cooldown**: Evita flapping (escala muito rÃ¡pida)

### ğŸ“¦ Exemplo PrÃ¡tico (deste projeto)
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: demo-app
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: demo-app          # Deployment alvo
  minReplicas: 2            # MÃ­nimo de Pods
  maxReplicas: 5            # MÃ¡ximo de Pods
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 50  # Meta: 50% de CPU
```

### ğŸ”§ Como Funciona

#### Algoritmo de Escala
```
desiredReplicas = ceil[currentReplicas * (currentMetric / targetMetric)]
```

**Exemplo**:
- **RÃ©plicas atuais**: 2
- **CPU atual**: 150% (mÃ©dia entre os Pods)
- **CPU alvo**: 50%
- **CÃ¡lculo**: `ceil[2 * (150 / 50)] = ceil[6] = 6`
- **Resultado**: Escala para 5 (limitado por maxReplicas)

#### Ciclo de Escala
```
1. metrics-server coleta mÃ©tricas
2. HPA calcula mÃ©dia
3. MÃ©trica > Alvo? â†’ Scale Out (+Pods)
4. MÃ©trica < Alvo? â†’ Scale In (-Pods)
5. MÃ©trica = Alvo? â†’ Manter rÃ©plicas
6. Aguardar cooldown â†’ Repetir
```

### ğŸ“Š Tipos de MÃ©tricas

#### 6.1 Resource (CPU/MemÃ³ria)
```yaml
metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
```

#### 6.2 Pods (mÃ©tricas customizadas por Pod)
```yaml
metrics:
  - type: Pods
    pods:
      metric:
        name: http_requests_per_second
      target:
        type: AverageValue
        averageValue: "1000"
```

#### 6.3 Object (mÃ©tricas de objetos K8s)
```yaml
metrics:
  - type: Object
    object:
      metric:
        name: requests-per-second
      describedObject:
        apiVersion: networking.k8s.io/v1
        kind: Ingress
        name: main-route
      target:
        type: Value
        value: "10k"
```

### ğŸ” Comandos Ãšteis
```bash
# Listar HPAs
kubectl get hpa

# Ver detalhes em tempo real
kubectl get hpa demo-app -w

# Detalhes do HPA
kubectl describe hpa demo-app

# Ver mÃ©tricas dos Pods
kubectl top pods

# Ver mÃ©tricas dos Nodes
kubectl top nodes

# Deletar HPA
kubectl delete hpa demo-app
```

### ğŸ“ˆ DemonstraÃ§Ã£o de Escala (deste projeto)

#### Gerar Carga
```bash
# Local (50 concorrentes, 2000 requisiÃ§Ãµes)
seq 2000 | xargs -n1 -P50 -I{} curl -s "http://localhost:30080/cpu?ms=100" >/dev/null

# No cluster (por 60 segundos)
kubectl run load --restart=Never --image=busybox -- \
  /bin/sh -c 'end=$((`date +%s`+60)); while [ `date +%s` -lt $end ]; do wget -q -O- http://demo-app.default.svc.cluster.local/cpu?ms=100 >/dev/null; done'
```

#### Observar Escala
```bash
# Terminal 1: HPA
kubectl get hpa demo-app -w
# NAME       REFERENCE             TARGETS    MINPODS   MAXPODS   REPLICAS
# demo-app   Deployment/demo-app   15%/50%    2         5         2
# demo-app   Deployment/demo-app   180%/50%   2         5         2
# demo-app   Deployment/demo-app   180%/50%   2         5         4
# demo-app   Deployment/demo-app   90%/50%    2         5         5
# demo-app   Deployment/demo-app   45%/50%    2         5         5
# demo-app   Deployment/demo-app   12%/50%    2         5         5
# demo-app   Deployment/demo-app   12%/50%    2         5         2

# Terminal 2: Pods
kubectl get pods -l app=demo-app -w
```

### âš™ï¸ PrÃ©-requisitos para HPA

#### 1. metrics-server instalado
```bash
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

# Docker Desktop: patch para TLS inseguro
kubectl -n kube-system patch deployment metrics-server --type='json' \
  -p='[{"op":"add","path":"/spec/template/spec/containers/0/args/-","value":"--kubelet-insecure-tls"}]'

# Verificar
kubectl top pods
```

#### 2. Resources definidos no Deployment
```yaml
resources:
  requests:
    cpu: "50m"      # OBRIGATÃ“RIO para HPA baseado em CPU
    memory: "64Mi"
  limits:
    cpu: "250m"
    memory: "128Mi"
```

### ğŸ†š HPA vs Escala Manual

| Aspecto | Escala Manual | HPA |
|---------|--------------|-----|
| **AutomaÃ§Ã£o** | âŒ Manual | âœ… AutomÃ¡tico |
| **ReaÃ§Ã£o** | Lenta | RÃ¡pida |
| **MÃ©tricas** | NÃ£o usa | Baseado em mÃ©tricas |
| **Custo** | Fixo | Otimizado |
| **Complexidade** | Simples | Requer setup |
| **Uso** | Dev/Test | ProduÃ§Ã£o |

---

## 10. ComparaÃ§Ã£o entre Componentes

### ğŸ“Š Tabela Resumida

| Componente | FunÃ§Ã£o | Escopo | Gerencia |
|-----------|--------|--------|----------|
| **Pod** | Unidade de execuÃ§Ã£o | Containers | N/A |
| **Deployment** | Gerencia Pods stateless | ReplicaSets/Pods | Pods |
| **StatefulSet** | Gerencia Pods stateful | Pods com identidade | Pods + PVCs |
| **Service** | ExpÃµe Pods | Rede | Endpoints |
| **ConfigMap** | ConfiguraÃ§Ã£o | Dados nÃ£o-sensÃ­veis | N/A |
| **Secret** | Credenciais | Dados sensÃ­veis | N/A |
| **PV** | Storage fÃ­sico | Cluster | Armazenamento |
| **PVC** | RequisiÃ§Ã£o de storage | Namespace | Bind com PV |
| **HPA** | Autoscaling | RÃ©plicas | Deployment/StatefulSet |

### ğŸ”— RelaÃ§Ãµes entre Componentes

**Workload Stateless**:
```
HPA â†’ escala â†’ Deployment â†’ cria â†’ ReplicaSet â†’ gerencia â†’ Pods
Pods â†’ consomem â†’ ConfigMap + Secret
Service â†’ seleciona â†’ Pods (via labels)
metrics-server â†’ coleta mÃ©tricas â†’ Pods â†’ fornece para â†’ HPA
```

**Workload Stateful**:
```
StatefulSet â†’ cria â†’ Pods (mysql-0, mysql-1, mysql-2)
Pods â†’ usam â†’ PVCs (PVC-0, PVC-1, PVC-2)
PVCs â†’ bind â†’ PVs (storage persistente)
Pods â†’ consomem â†’ ConfigMap + Secret
Headless Service â†’ DNS estÃ¡vel por Pod
```

### ğŸ¯ Fluxo de RequisiÃ§Ã£o

```
1. Cliente â†’ HTTP Request â†’ Service
2. Service â†’ Load Balance â†’ Seleciona Pod
3. Pod â†’ LÃª ConfigMap (VERSION)
4. Pod â†’ LÃª Secret (SECRET_TOKEN)
5. Pod â†’ Processa requisiÃ§Ã£o
6. Pod â†’ HTTP Response â†’ Service â†’ Cliente
```

---

## ğŸ“ Resumo Executivo

### Quando usar cada componente?

| Componente | Use quando... |
|-----------|--------------|
| **Pod** | Nunca diretamente em produÃ§Ã£o (use Deployment/StatefulSet) |
| **Deployment** | AplicaÃ§Ãµes stateless (APIs, web apps, workers) |
| **StatefulSet** | AplicaÃ§Ãµes stateful (bancos de dados, Kafka, Redis) |
| **Service** | Sempre que precisar expor Pods (interno ou externo) |
| **ConfigMap** | ConfiguraÃ§Ãµes nÃ£o-sensÃ­veis (flags, URLs, configs) |
| **Secret** | Dados sensÃ­veis (senhas, tokens, chaves, certificados) |
| **PV/PVC** | Storage persistente (bancos, uploads, logs) |
| **HPA** | Carga variÃ¡vel e necessidade de otimizaÃ§Ã£o de recursos |

### DecisÃ£o: Deployment vs StatefulSet?

```bash
# Use Deployment se:
âœ… AplicaÃ§Ã£o stateless (nÃ£o mantÃ©m estado local)
âœ… Pods sÃ£o intercambiÃ¡veis (qualquer Pod pode processar qualquer requisiÃ§Ã£o)
âœ… NÃ£o precisa de storage persistente por Pod
âœ… Ordem de criaÃ§Ã£o/exclusÃ£o nÃ£o importa
Exemplos: APIs REST, Web servers, Workers

# Use StatefulSet se:
âœ… AplicaÃ§Ã£o stateful (mantÃ©m estado local)
âœ… Cada Pod tem identidade Ãºnica
âœ… Precisa de storage persistente por Pod
âœ… Ordem de criaÃ§Ã£o/exclusÃ£o importa
âœ… Precisa de DNS estÃ¡vel por Pod
Exemplos: MySQL, PostgreSQL, MongoDB, Kafka, Redis, ZooKeeper
```

### DecisÃ£o: Qual tipo de Service?

```bash
# ClusterIP (padrÃ£o)
âœ… ComunicaÃ§Ã£o interna no cluster
Exemplo: Backend API, Banco de dados

# NodePort
âœ… Desenvolvimento local (Docker Desktop, Minikube)
Exemplo: Testar app localmente

# LoadBalancer
âœ… ProduÃ§Ã£o em cloud (AWS, GCP, Azure)
Exemplo: API pÃºblica, Website

# ExternalName
âœ… Referenciar serviÃ§os externos
Exemplo: AWS RDS, APIs externas
```

### Ordem de criaÃ§Ã£o recomendada

#### Para aplicaÃ§Ãµes stateless (Deployment):
```
1. ConfigMap/Secret (configuraÃ§Ã£o)
2. Deployment (workload)
3. Service (rede)
4. HPA (autoscaling - opcional)
```

#### Para aplicaÃ§Ãµes stateful (StatefulSet):
```
1. ConfigMap/Secret (configuraÃ§Ã£o)
2. StorageClass (se nÃ£o existir)
3. Headless Service (clusterIP: None)
4. StatefulSet (com volumeClaimTemplates)
5. Service (para acesso externo - opcional)
```

### Comandos essenciais

```bash
# Ver tudo
kubectl get all

# Ver com labels
kubectl get all -l app=demo-app

# Logs
kubectl logs -f deployment/demo-app

# Escala
kubectl scale deployment demo-app --replicas=3

# Port-forward (debug)
kubectl port-forward deployment/demo-app 8080:8080

# Executar comando
kubectl exec -it deployment/demo-app -- /bin/sh

# Deletar tudo
kubectl delete all -l app=demo-app
```

---

## ğŸ“š ReferÃªncias

- [Kubernetes Documentation](https://kubernetes.io/docs/)
- [Pod Lifecycle](https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/)
- [Deployments](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/)
- [Services](https://kubernetes.io/docs/concepts/services-networking/service/)
- [ConfigMaps](https://kubernetes.io/docs/concepts/configuration/configmap/)
- [Secrets](https://kubernetes.io/docs/concepts/configuration/secret/)
- [HPA](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/)

---

**Projeto**: demo-kubernetes-local  
**VersÃ£o**: 1.0  
**Ãšltima atualizaÃ§Ã£o**: 2024
